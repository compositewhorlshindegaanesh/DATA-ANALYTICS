{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbf3203e",
   "metadata": {},
   "source": [
    "# Statistics — Assignment DA-AG-006\n",
    "Solved by ChatGPT\n",
    "\n",
    "This notebook includes concise theory answers and runnable code for the practical questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfd5f2f",
   "metadata": {},
   "source": [
    "## Theory Questions (Q1 - Q8)\n",
    "\n",
    "**Question 1:**\n",
    "\n",
    "A random variable is a numerical quantity whose value depends on the outcome of a random phenomenon. Formally, it is a function that assigns a real number to each outcome in a probability space.\n",
    "\n",
    "**Question 2:**\n",
    "\n",
    "Types: (a) Discrete random variables — take countable values (e.g., 0,1,2,...). (b) Continuous random variables — take values in an interval (uncountably infinite), described by probability density functions.\n",
    "\n",
    "**Question 3:**\n",
    "\n",
    "Discrete distributions assign probabilities to individual outcomes (e.g., Binomial, Poisson). Continuous distributions use densities and probabilities are areas under the density curve (e.g., Normal, Exponential). Discrete PMF sums to 1; continuous PDF integrates to 1.\n",
    "\n",
    "**Question 4:**\n",
    "\n",
    "Binomial distribution models the number of successes in n independent Bernoulli trials with success probability p. P(X=k)=C(n,k)p^k(1-p)^{n-k}. Used for yes/no repeated experiments (e.g., defective items in a sample).\n",
    "\n",
    "**Question 5:**\n",
    "\n",
    "The standard normal distribution is the Normal(0,1) (mean 0, sd 1). It's important because many statistics can be standardized to it (z-scores), and it serves as the reference for normal-theory inference (tables, z-tests).\n",
    "\n",
    "**Question 6:**\n",
    "\n",
    "Central Limit Theorem (CLT): For a large sample size n, the distribution of the sample mean (or sum) of i.i.d. random variables approaches a normal distribution with mean equal to the population mean and variance equal to population variance/n, regardless of the original distribution's shape. Critical because it justifies using normal-based inference (confidence intervals, hypothesis tests) even when the population is not normal.\n",
    "\n",
    "**Question 7:**\n",
    "\n",
    "Confidence intervals provide a range of plausible values for an unknown parameter (e.g., population mean). A 95% CI means that, over many repeated samples, 95% of such intervals will contain the true parameter. They convey uncertainty in point estimates.\n",
    "\n",
    "**Question 8:**\n",
    "\n",
    "Expected value (mean) of a random variable is the long-run average value: for discrete X, E[X]=sum x * P(X=x); for continuous X, E[X]=∫ x f(x) dx. It measures the central tendency of the distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557cf0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 9\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "samples = np.random.normal(loc=50, scale=5, size=1000)\n",
    "print(\"Sample mean:\", samples.mean())\n",
    "print(\"Sample std (ddof=1):\", samples.std(ddof=1))\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(samples, bins=30)\n",
    "plt.title(\"Histogram of 1000 samples from N(50,5^2)\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6c49cc",
   "metadata": {},
   "source": [
    "## Question 10 — CLT application and 95% CI for average daily sales\n",
    "\n",
    "**Approach (using CLT):**\n",
    "- The Central Limit Theorem tells us that the distribution of the sample mean is approximately normal when sample size is reasonably large (common rule: n ≥ 30). For smaller n, if the original data are not strongly non-normal, the t-distribution gives better coverage.\n",
    "- We compute the sample mean \\(\\bar{x}\\), sample standard deviation s, standard error \\(SE = s/\\sqrt{n}\\), and then a 95% confidence interval:\n",
    "  - If using t-distribution: \\(\\bar{x} \\pm t_{0.975, n-1} \\times SE\\).\n",
    "  - If using normal approx (z): \\(\\bar{x} \\pm 1.96 \\times SE\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd7e6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 10 code: compute mean and 95% CI for daily_sales\n",
    "import numpy as np, math\n",
    "daily_sales = [220, 245, 210, 265, 230, 250, 260, 275, 240, 255, 235, 260, 245, 250, 225, 270, 265, 255, 250, 260]\n",
    "n = len(daily_sales)\n",
    "mean_sales = np.mean(daily_sales)\n",
    "std_sales = np.std(daily_sales, ddof=1)\n",
    "se = std_sales / math.sqrt(n)\n",
    "\n",
    "try:\n",
    "    from scipy import stats\n",
    "    t_crit = stats.t.ppf(0.975, df=n-1)\n",
    "    crit_name = f\"t (df={n-1})\"\n",
    "except Exception:\n",
    "    t_crit = 1.96\n",
    "    crit_name = \"z (normal approx)\"\n",
    "\n",
    "ci_lower = mean_sales - t_crit * se\n",
    "ci_upper = mean_sales + t_crit * se\n",
    "\n",
    "print(\"n =\", n)\n",
    "print(\"Sample mean =\", mean_sales)\n",
    "print(\"Sample sd (ddof=1) =\", std_sales)\n",
    "print(\"Standard error =\", se)\n",
    "print(f\"Using critical value: {t_crit} ({crit_name})\")\n",
    "print(f\"95% CI for mean: [{ci_lower:.3f}, {ci_upper:.3f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79469eb7",
   "metadata": {},
   "source": [
    "### Files saved with this notebook\n",
    "- Histogram image (Q9): `q9_histogram.png`\n",
    "- Notebook: `Statistics_Assignment.ipynb`\n",
    "\n",
    "You can download the notebook file and open it in Google Colab (File → Upload notebook) or GitHub.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
